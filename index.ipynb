{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digits, SVD classification, and randomness\n",
    "_What does it mean to be random?_\n",
    "\n",
    "The key parameter of our SVD-based handwritten digit classifier is $k$. The projection matrices we use during classification are computed using the first $k$ singular vectors.\n",
    "\n",
    "Recall that when $k=256$ (the full dimension of the data), each projection matrix is (at least theoretically) $UU^\\top = I$. This means all our errors should be equal to zero, which of course doesn't help us classify digits (in fact, the algorithm performs worst when $k=256$).\n",
    "\n",
    "But in class you may have noticed that even this worst-case performance seemed high. You might have seen over 70% accuracy even with $k=256$! What's going on here? Shouldn't the classification be random? Shouldn't the accuracy be closer to 10%?\n",
    "\n",
    "Clearly there is some non-randomness in our data or our algorithm. Let's look for it.\n",
    "\n",
    "_This notebook contains Python code, but don't worry if you aren't familiar with Python. All you need to do is run each cell and play with the output._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "Run the following cell to load some code and our digit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-10T16:55:05.083764",
     "start_time": "2016-10-10T16:55:04.262137"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import ipywidgets as ipw\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# contains classify_image and related fcns:\n",
    "from eigenimages import *\n",
    "\n",
    "# load data\n",
    "trn = loadmat(\"TRAIN_DIGITS.mat\")[\"TRAIN_DIGITS\"]\n",
    "testdata = loadmat(\"TEST_DIGITS.mat\")\n",
    "tst = testdata[\"TEST_DIGITS\"]\n",
    "labels = testdata[\"TEST_DIGIT_LABELS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of test data\n",
    "\n",
    "One potential source of non-randomness lies in our data. What if we have different numbers of various digits? Let's look at the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-10T16:58:06.610030",
     "start_time": "2016-10-10T16:58:06.218924"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute the number of occurrences of each digit\n",
    "digit_counts = np.zeros(10)\n",
    "for i in range(10):\n",
    "    digit_counts[i] = sum(labels == i)\n",
    "\n",
    "# plot\n",
    "fig = figure(figsize=(6,4))\n",
    "xl = (-0.5,9.5)\n",
    "yl = (100,400)\n",
    "markerline, stemlines, baseline = stem(range(10), digit_counts, linefmt='k-', markerfmt='ko')\n",
    "setp(stemlines, alpha=0.3)\n",
    "title('Test Digit Distribution')\n",
    "xlabel('Digit')\n",
    "ylabel('Number of test digits')\n",
    "xlim(xl)\n",
    "ylim(yl)\n",
    "xticks(range(10))\n",
    "twinx()\n",
    "ylabel('Fraction of test digits')\n",
    "xlim(xl)\n",
    "ylim(yl/sum(digit_counts))\n",
    "yticks\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so the digit \"0\" is over-represented among our test digit dataset. By contrast, only 7.5% of the test digits are \"7\". This might help explain why our algorithm appears to have non-random behavior when $k=256$.\n",
    "\n",
    "**Why would this dataset have more zeros and ones than fives and sevens?*\n",
    "\n",
    "One possible explanation is that real datasets (like the subset of [MNIST][1] we are using) actually exhibit this behavior. This phenomenon is referred to as [Benford's Law][2].\n",
    "\n",
    "Now let's look at the distribution of our computer's \"random\" predictions when $k=256$.\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/MNIST_database\n",
    "[2]: https://en.wikipedia.org/wiki/Benford%27s_law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of predictions\n",
    "\n",
    "Another potential source of non-randomness is the prediction algorithm itself. Rounding errors may cause our projection matrices to be slightly different from the identity matrix, so our classification errors may not be exactly zero. Even if the errors were all identical, the computer may not \"roll a fair die\" when confronted with multiple equal values -- it may choose the last in the set of identical values, for instance.\n",
    "\n",
    "Let's plot the distribution of predictions for $k=256$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-07T10:04:59.386295",
     "start_time": "2016-10-07T10:04:58.514746"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classify all digits\n",
    "k = 256\n",
    "predictions = classify_image(tst,trn,k)\n",
    "\n",
    "# compute the number of occurrences of each digit prediction\n",
    "prediction_counts = np.zeros(10)\n",
    "for i in range(10):\n",
    "    prediction_counts[i] = sum(predictions == i)\n",
    "\n",
    "# plot \n",
    "fig = figure(figsize=(6,4))\n",
    "xl = (-0.5,9.5)\n",
    "yl = (0,800)\n",
    "markerline, stemlines, baseline = stem(range(10), prediction_counts, \n",
    "                                       linefmt='k-', markerfmt='ko')\n",
    "setp(stemlines, alpha=0.3)\n",
    "title('Prediction Distribution')\n",
    "xlabel('Digit')\n",
    "ylabel('Number of predicted digits')\n",
    "# xlim(xl)\n",
    "# ylim(yl)\n",
    "xticks(range(10))\n",
    "twinx()\n",
    "ylabel('Fraction of predicted digits')\n",
    "xlim(xl)\n",
    "ylim(yl/sum(prediction_counts))\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive: overlay of both distributions\n",
    "\n",
    "Run the following cell to generate an interactive overlay of the test digit and prediction distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-10T17:01:13.500552",
     "start_time": "2016-10-10T17:01:12.237378"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "xl = np.array([-0.5,9.5])\n",
    "yl = np.array([0,800])\n",
    "fig = figure(figsize=(6,4))\n",
    "ax_l = fig.add_subplot(111)\n",
    "ax_l.set_xlim(xl)\n",
    "ax_l.set_ylim(yl)\n",
    "ax_l.set_xticks(range(10))\n",
    "ax_l.set_xlabel('Digit')\n",
    "ax_l.set_ylabel('Number of occurrences')\n",
    "ax_l.xaxis.grid()\n",
    "\n",
    "ax_r = ax_l.twinx()\n",
    "ax_r.set_ylim(yl/np.float(size(labels)))\n",
    "ax_r.set_ylabel('Fraction of all digits')\n",
    "\n",
    "vals = ax_r.get_yticks()\n",
    "ax_r.set_yticklabels(['{:3.0f}%'.format(x*100) for x in vals])\n",
    "\n",
    "m1, s1, b1 = ax_l.stem(arange(10), digit_counts, \n",
    "                  linefmt='k-', markerfmt='bo')\n",
    "setp(s1, alpha=0)\n",
    "setp(b1,lw=0)\n",
    "\n",
    "prediction_counts = np.zeros(10)\n",
    "m2, s2, b2 = ax_l.stem(arange(10), prediction_counts, \n",
    "                  linefmt='k-', markerfmt='ro')\n",
    "setp(s2, alpha=0)\n",
    "setp(b2,lw=0)\n",
    "\n",
    "ax_l.legend(['Test Data Labels','Prediction Labels'], fontsize=10)\n",
    "\n",
    "def on_change(k):\n",
    "    # classify all digits\n",
    "    predictions = classify_image(tst,trn,k)\n",
    "\n",
    "    # compute the number of occurrences of each digit prediction\n",
    "    prediction_counts = np.zeros(10)\n",
    "    for i in range(10):\n",
    "        prediction_counts[i] = sum(predictions == i)\n",
    "\n",
    "    m2.set_ydata(prediction_counts)\n",
    "    ax_r.set_title('Prediction Distribution (accuracy = {:3.0f}%)'.format(100*sum(predictions == labels)/size(labels)))\n",
    "    return fig\n",
    "\n",
    "ipw.interact(on_change, k=ipw.IntSlider(min=1,max=256,step=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of the two distributions is flat, and the final accuracy of the algorithm depends on both of them.\n",
    "\n",
    "**Set $k=220$ by clicking on the number next to the slider and typing it in. Can you explain why the accuracy is so high by looking at the plot?**\n",
    "\n",
    "**Now set $k=256$ and look at the distribution of prediction labels.**\n",
    "\n",
    "The algorithm predicts 3, 4, or 5 90% of the time! Not very random..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: which pairs of digits are difficult to distinguish?\n",
    "\n",
    "Another way to look at our classification algorithm is to compute a 10-by-10 matrix $X$ where $X[i,j]$ element is the fraction of digit $j$ classified as digit $i$ by the algorithm. In other words, if $X[3,4] = 0.09$, the algorithm classified 9% of the \"4\"s as \"3\"s.\n",
    "\n",
    "**What should each column of $X$ sum to?**\n",
    "\n",
    "Now run the following cell to generate $X$ for any value of $k$ you choose. Note the \"Color adjust\" slider, which determines the black threshold. You may need to drag this slider down so you can see the lighter-colored squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-10T17:01:29.968674",
     "start_time": "2016-10-10T17:01:28.614745"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prediction_by_digit(predictions, labels):\n",
    "    \"\"\"\n",
    "    Return a matrix whose [i,j] element equals the fraction of test\n",
    "    digits with label j are predicted to be digit i. (Cols sum to 1.)\n",
    "    \"\"\"\n",
    "    prediction_spread = np.zeros((10,10))\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            prediction_spread[i,j] = sum(predictions[labels == j] == i)/np.float(sum(labels == j))\n",
    "    return prediction_spread\n",
    "\n",
    "fig = figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111)\n",
    "set_cmap('gray_r')\n",
    "im = ax.imshow(np.zeros((10,10)), interpolation='nearest')\n",
    "im.set_clim((0,0.6))\n",
    "colorbar(im)\n",
    "\n",
    "xlabel('Test digit')\n",
    "ylabel('Predicted digit')\n",
    "xticks(range(10))\n",
    "yticks(range(10))\n",
    "\n",
    "labels = labels.squeeze()\n",
    "def on_change(val,cmax):\n",
    "    predictions = classify_image(tst,trn,val)\n",
    "    prediction_spread = prediction_by_digit(predictions, labels)\n",
    "\n",
    "    im.set_data(prediction_spread)\n",
    "    fig.canvas.draw()\n",
    "    ax.set_title('Prediction accuracy: ' + str(round(100*sum(predictions == labels)/size(labels),0)) + '%')\n",
    "    im.set_clim((0,cmax))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "ipw.interact(on_change,\n",
    "             val=ipw.IntSlider(\n",
    "        min=1,\n",
    "        max=256,\n",
    "        step=10,\n",
    "        description=\"k:\",\n",
    "        width=200),\n",
    "             cmax=ipw.FloatSlider(\n",
    "        description='Color adjust',\n",
    "        min=0.2,\n",
    "        max=1.0,\n",
    "        step=0.1,\n",
    "        value=1.0)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would this plot look like ideally?**\n",
    "\n",
    "**What value of $k$ comes closest to this ideal?**\n",
    "\n",
    "**Why is there such a big difference in the plot between $k=255$ and $k=256$?**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
